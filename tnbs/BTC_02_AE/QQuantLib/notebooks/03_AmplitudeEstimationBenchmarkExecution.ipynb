{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f1389b36-6736-447a-a207-f13e3422798e",
   "metadata": {},
   "source": [
    "# Execution of Amplitude Estimation Benchmark\n",
    "\n",
    "In this notebook we explain how to execute a **AE** benchmark. As explained at the end of the notebook *02_AmplitudeEstimationBTC.ipynb* the module **BTC_02_AE/ae_sine_integral** gathers all the mandatory code for executing a complete integral using a selected **AE** algorithm. \n",
    "\n",
    "For executing a benchmark following the guidelines of the **TNBS** we need to perform several executions and do some statistics on the obtained repetitions results. Aditionally we need to procces the results for generating the mandatory **TNBS JSON** document. This is done by the following modules:\n",
    "* my_benchmark_execution.py\n",
    "* neasqc_benchmark.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "380af109-10b2-4fec-b693-9cdb78fd2285",
   "metadata": {},
   "source": [
    "## 1. my_benchmark_execution\n",
    "\n",
    "A complete benchmark execution following the **TNBS** guidelines can be performed by using the **my\\_benchmark\\_execution.py** module in the **BTC_02_AE** folder.\n",
    "\n",
    "The desired **AE** algorithm should be set at the variable **AE** at the end part of the **my_benchmark_execution.py** file. For configuring the algorithm the corresponding JSON file, in the **jsons** folder, should be edited:\n",
    "\n",
    "* integral_cqpeae_configuration.json: configure **CQPEAE**\n",
    "* integral_iqpeae_configuration.json: configure **IQPEAE**\n",
    "* integral_mlae_configuration.json: configure **MLAE**\n",
    "* integral_iqae_configuration.jso: configure **IQAE**Ã‡\n",
    "*  integral_rqae_configuration.jso: configure **RQAE**\n",
    "* integral_mcae_configuration.json: configure **MCAE**\n",
    "\n",
    "Additionally, the list with the number of qubits that want to be tested can be provided by editing the key: *list_of_qbits* of the *benchmark_arguments* dictionary (at the end of the module).\n",
    "\n",
    "For changing the folder where all the files generated by the benchmark are stored the path can be provided to the key *saving_folder*  of the *benchmark_arguments*.\n",
    "\n",
    "For executing the complete benchmark you can use the following command:\n",
    "\n",
    "    python my_benchmark_execution.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35f90928-7e6e-4d34-bbf8-2dbf6ec6eb87",
   "metadata": {},
   "source": [
    "## 2. Generating the JSON file.\n",
    "\n",
    "Once the files from a complete benchmark execution are generated the information should be formated following the **NEASQC JSON schema**. For doing this the **neasqc_benchmark.py** module can be used. At the end of the file the path to the folder where all the files from benchmark are stored should be provided to the variable **folder**.\n",
    "\n",
    "For creating the JSON file following command should eb executed:\n",
    "\n",
    "    python neasqc_benchmark.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "490620e7-62ab-45f7-b8a8-761bf4970497",
   "metadata": {},
   "source": [
    "## 3. Complete Workflow.\n",
    "\n",
    "The bash script **benchmark_exe.sh** allows to automatize the execution of the benchamrk and the JSON file generation (once the *my_benchmark_execution.py* and the *neasqc_benchmark.py* are properly configured).\n",
    "\n",
    "    bash benchmark_exe.sh"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tnbs] *",
   "language": "python",
   "name": "conda-env-tnbs-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
